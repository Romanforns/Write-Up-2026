<!DOCTYPE html>
<html lang="es">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="Write Up Román Forns – Septiembre 2025">
	<meta name="author" content="romanforns.com, romanforns@gmail.com">
	<title>Write Up – Román Forns</title>

	<link rel="shortcut icon" href="images/avatar.jpg">
	<link rel="apple-touch-icon-precomposed" sizes="144x144" href="images/ico/apple-touch-icon-144-precomposed.png">
	<link rel="apple-touch-icon-precomposed" sizes="114x114" href="images/ico/apple-touch-icon-114-precomposed.png">
	<link rel="apple-touch-icon-precomposed" sizes="72x72" href="images/ico/apple-touch-icon-72-precomposed.png">
	<link rel="apple-touch-icon-precomposed" href="images/ico/apple-touch-icon-57-precomposed.png">

	<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css" />
	<link rel="stylesheet" type="text/css" href="css/materialdesignicons.min.css" />
	<link rel="stylesheet" type="text/css" href="css/template.css" />
</head>
<body>
	<div id="nino-cvWrap">

		<section id="profile-banner">
			<header class="profile-header">
				<h2 class="page-title">Write Up Q1 2026</h2>
				<img src="images/avatar.jpg" alt="Foto de Román Forns" class="avatar">
				<h1 class="name">Román Forns</h1>
				<h3 class="regency">Data Platform Architect</h3>
			</header>
		</section>

		<nav id="mainMenu">
			<ul class="nav-main">
				<li><a href="#growth" class="topBar"><i class="mdi mdi-trending-up nino-icon"></i>CRECIMIENTO</a></li>
				<li class="nav-dropdown-wrap">
					<a href="#dimensions-growth" class="topBar nav-dropdown-trigger"><i class="mdi mdi-source-branch nino-icon"></i>SDG DIMENSIONS</a>
				</li>
				<li><a href="#activities" class="topBar"><i class="mdi mdi-clipboard-text nino-icon"></i>ENTREGABLES</a></li>
				<li><a href="#future" class="topBar"><i class="mdi mdi-timer-sand nino-icon"></i>FUTURO</a></li>
				<li><a href="#growth-factors" class="topBar"><i class="mdi mdi-rocket nino-icon"></i>CLAVES</a></li>
				<li><a href="#personal-comment" class="topBar"><i class="mdi mdi-comment-text nino-icon"></i>COMENTARIOS</a></li>
			</ul>
			<ul class="nav-submenu">
				<li><a href="#practice" class="topBar"><i class="mdi mdi-briefcase nino-icon"></i>PRÁCTICA</a></li>
				<li><a href="#operations" class="topBar"><img src="images/operations-logo.svg" alt="OPERACIONES" class="nino-icon operations-logo">OPERACIONES</a></li>
				<li><a href="#team" class="topBar"><i class="mdi mdi-account-multiple nino-icon"></i>EQUIPO</a></li>
				<li><a href="#client" class="topBar"><i class="mdi mdi-domain nino-icon"></i>CLIENTE</a></li>
				<li><a href="#business" class="topBar"><i class="mdi mdi-cash-multiple nino-icon"></i>NEGOCIO</a></li>
				<li><a href="#influence" class="topBar"><i class="mdi mdi-chart-line nino-icon"></i>INFLUENCIA</a></li>
			</ul>
		</nav>

		<div layout="row" class="fw">
			<div id="nino-rightSide" class="fg">
				<main id="nino-mainContent">
					<section id="github-stats">
						<div class="github-header-icon">
							<i class="mdi mdi-github-circle"></i>
						</div>
						<div class="nino-sectionContent github-heatmap">
							<a href="https://github.com/romanforns" target="_blank" rel="noopener noreferrer">
								<img src="https://ghchart.rshah.org/romanforns" alt="Histórico de contribuciones en GitHub de romanforns" class="github-contributions">
							</a>
						</div>
					</section>
					<section id="growth" class="section-collapsible collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-trending-up nino-icon"></i>¿Sientes que has crecido en los últimos 6 meses?
						</h2>
						<div class="nino-sectionContent">
							<p>
								En estos últimos seis meses he experimentado una evolución muy significativa. Los proyectos en los que he participado me han exigido dominar nuevas plataformas y patrones (Microsoft Fabric, Data Vault, arquitecturas metadata-driven, modelado con dbt), asumiendo el liderazgo técnico tanto en la fase de diseño como durante la implementación.
							</p>
						</div>
					</section>

					<section id="dimensions-growth" class="section-collapsible collapsed">
						<h2 class="nino-sectionHeading dimensions-heading">
							<i class="mdi mdi-source-branch nino-icon"></i>Dimensiones del crecimiento profesional
						</h2>
					</section>

					<section id="practice" class="dimension-section collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-briefcase nino-icon"></i>PRÁCTICA
						</h2>
						<div class="nino-sectionContent">
							<div class="inner">
								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Assessment Migración DACSA</h3>
									<div class="nino-articleContent">
										<p>
										<p>
											A partir de la extracción automatizada de metadatos de Dataverse, Azure Synapse, Azure Data Factory, MySQL y Power BI, mediante herramientas propias desarrolladas en Python, he generado el inventario completo de la plataforma de Business Intelligence. Sobre esta base, he elaborado una <a href="https://github.com/Romanforns/migracion_dacsa/blob/master/Assessment_Migracion_Fabric_DACSA.md#productos-documentados" target="_blank" rel="noopener noreferrer"><strong>documentación exhaustiva de la arquitectura y los activos existentes, incluyendo modelos semánticos, reportes paginados, transformaciones ETL</strong></a>, análisis de linaje por dominio (Finanzas, Logística, Ventas, Calidad, I+D y POE) y diagramas de dependencias técnicas y funcionales.
										</p>
										</p>
										<p>
											Asimismo, he definido <a href="https://github.com/Romanforns/migracion_dacsa/blob/master/Assessment_Migracion_Fabric_DACSA.md#categorización-de-productos" target="_blank" rel="noopener noreferrer"><strong>criterios de categorización de productos según su nivel de complejidad (S, M, L, XL)</strong></a> para estructurar y planificar su migración a Microsoft Fabric. Este marco de clasificación, junto con la documentación exhaustiva de la arquitectura, ha permitido al equipo realizar un <a href="https://docs.google.com/spreadsheets/d/1jjGVUZ-GT-S37_2Pfa-CA0RfkMlHH7aloJaicl6n3Os/edit?gid=647132170#gid=647132170" target="_blank" rel="noopener noreferrer"><strong>análisis de la plataforma de forma sistemática, estimar el esfuerzo requerido y dimensionar con precisión el alcance del proyecto de migración, convirtiéndose en el principal input para la elaboración y defensa de la propuesta comercial.</strong></a>
										</p>
									</div>
								</article>

								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Proyecto Migración DACSA Fabric</h3>
									<div class="nino-articleContent">
										<p>
											Sobre la base del assessment previo, se llevó a cabo el <a href="https://www.notion.so/DACSA-Microsoft-Fabric-2e809578a317804d8313c20b19f92ad3" target="_blank" rel="noopener noreferrer"><strong>análisis y diseño de la migración hacia Microsoft Fabric.</strong></a> Se abordó una <a href="https://github.com/Romanforns/DACSA/tree/refinamiento_dependencias_entidades/FINANZAS/Queries%20Sincronizadas" target="_blank" rel="noopener noreferrer"><strong>simplificación integral de la capa de transformación</strong></a>, orientándola a la ingesta directa de entidades de D365 F&amp;O y a la aplicación sistemática de <a href="https://www.notion.so/Guia-Tests-Calidad-DBT-2f509578a31780b594b8f8bd13aa8a46" target="_blank" rel="noopener noreferrer"><strong>reglas de calidad definidas en una guía metodológica exhaustiva</strong></a>, diseñada para maximizar el uso de las librerías dbt_utils y dbt_expectations (validaciones de integridad, unicidad, rangos, formatos y consistencia dentro del marco de arquitectura Medallion).
										</p>
										<p>
											En paralelo, se diseñó y estructuró el <strong>proyecto de modelado analítico con dbt</strong> para DACSA, organizando los modelos en capas <strong>Staging / Silver / Gold</strong> a partir de fuentes como Dynamics 365 y SharePoint, centralizando reglas de transformación en macros reutilizables y <code>schema.yml</code> con tests y documentación, e integrando el despliegue con pipelines de CI/CD en Azure Pipelines y flujos Git para promover cambios de forma trazable y gobernada.
										</p>
										<p>
											Como resultado, el dato queda estandarizado, validado y preparado en la capa Silver, mientras que en la capa Gold queda estructurado y listo para ser explotado directamente por los analistas de negocio. Para garantizar coherencia, trazabilidad y escalabilidad, se definieron <a href="https://www.notion.so/Data-Naming-Conventions-Guide-2e809578a3178082b102e2923a5329cb" target="_blank" rel="noopener noreferrer"><strong>guidelines transversales de Naming Conventions</strong></a> , estableciendo una clara diferenciación entre la capa Silver (enfoque técnico y trazable) y la capa Gold (enfoque semántico y orientado a negocio), con convenciones obligatorias para nuevos desarrollos. Asimismo, participé en el refinamiento de los pipelines de ingesta desde orígenes cloud y on-premises, basada en shortcuts y staging en Lakehouses.
										</p>
									</div>
								</article>

								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Prueba DataTech para promoción a Specialist</h3>
									<div class="nino-articleContent">
										<p>
										<p>
											El equipo de DataTech proporcionó inicialmente, a mi solicitud, dos ejemplos de prueba técnica y, días después, una tercera prueba final. Tras comenzar su desarrollo de forma independiente, se decidió <a href="https://docs.google.com/presentation/d/1_cjbw7L3pkZGD61f7ax-OyCHgLw3EoTq/present?slide=id.p2" target="_blank" rel="noopener noreferrer"><strong>consolidar los tres enunciados en una única Proof of Concept (PoC)</strong></a> integrada que diera respuesta conjunta a todos los requisitos planteados.
										</p>
										</p>
										<p>
											Las pruebas abordaban, respectivamente: el diseño de una arquitectura Data Vault 2.0 sobre TPCH_SF1 en Snowflake con dbt Cloud y lineage end-to-end; el desarrollo de un framework de ingesta y validación metadata-driven con PySpark, Docker y Airflow bajo un enfoque DataOps; y la implementación de un programa en Python/Scala basado en metadata.json para transformaciones dinámicas, control de calidad y versionado con Spark.
										</p>
										<p>
											Como respuesta, se diseñó una <a href="https://github.com/Romanforns/SDG_TEST_DataTech?tab=readme-ov-file#sdg-data-transformation-platform" target="_blank" rel="noopener noreferrer"><strong>solución unificada y metadata-driven que integró arquitectura, procesamiento, gobierno y modelado de datos en un mismo ecosistema tecnológico basado en Airflow, Spark y dbt sobre Snowflake</strong></a>. La propuesta combinó un framework de ingesta y validación declarativa y un motor de transformaciones dinámicas gobernado por metadatos JSON, garantizando trazabilidad, control de versiones y calidad del dato desde origen hasta la arquitectura Data Vault en la capa analítica.
										</p>
										<p>
											El proceso abarcó la ingesta desde Snowflake/Postgres hacia zona landing (Parquet), la aplicación de reglas de validación y enriquecimiento en Spark generando datasets OK/KO con quality markers, la carga versionada en capa RAW con estrategias overwrite/append/merge configuradas por metadatos, y la posterior materialización en <a href="https://github.com/Romanforns/SDG_TEST_DataTech/tree/main/dbt/models/data_vault" target="_blank" rel="noopener noreferrer"><strong>modelo Data Vault 2.0 (staging → hubs, links, satellites → marts)</strong></a>, incluyendo testing automatizado y lineage end-to-end. El resultado fue una plataforma unificada que resolvió los tres ejercicios en un único entregable coherente, demostrando capacidades avanzadas de diseño arquitectónico, estandarización de procesos mediante centralización de reglas y configuraciones en metadatos reutilizables, gobierno del dato y construcción de un framework reutilizable y escalable con documentación de nivel entrega/defensa que permite a terceros entender y operar la plataforma sin depender del equipo original.
										</p>
									</div>
								</article>

								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Metadata Driven Ingestion Framework (MDIF)</h3>
									<div class="nino-articleContent">
										<p>
										<p>
											Como ejercicio adicional, se desarrolló el proyecto <a href="https://github.com/Romanforns/Metadata-Driven-Ingestion-Framework#metadata-driven-ingestion-framework-mdif" target="_blank" rel="noopener noreferrer"><strong>Metadata Driven Ingestion Framework (MDIF), un framework de ingeniería de datos que automatiza la migración e ingesta entre PostgreSQL, MySQL y Snowflake mediante una arquitectura declarativa basada en metadatos YAML.</strong></a>
										</p>
										</p>
										<p>
											El sistema implementa una arquitectura en capas que separa completamente la configuración de la implementación: la capa de metadatos centraliza la configuración declarativa en YAML; la capa de generación realiza descubrimiento automático de esquemas desde INFORMATION_SCHEMA, valida y normaliza metadatos, y genera automáticamente scripts DDL idempotentes y scripts Python parametrizados para ingesta; la capa de runtime abstrae conexiones mediante el patrón Strategy e implementa estrategias de ingesta batch e incrementales con mapeo automático de tipos entre sistemas heterogéneos; y la capa de orquestación integra el flujo completo con Apache Airflow.
										</p>
										<p>
											El framework incorpora características avanzadas como control de volumetría (límites absolutos o porcentuales), procesamiento en streaming para tablas grandes, verificación de integridad post-ingesta, manejo robusto de errores con retry logic y ejecución idempotente de todas las operaciones. El proyecto continúa evolucionando con la incorporación de nuevos conectores y la extensión del patrón metadata-driven a otros escenarios de migración, con el objetivo de consolidarse como un activo reutilizable y escalable dentro del portfolio de soluciones de la práctica, eliminando código repetitivo y estandarizando procesos de migración.
										</p>
									</div>
								</article>

								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Proyecto Refactorización DataPlatform TOUS</h3>
									<div class="nino-articleContent">
										<p>
										<p>
											A partir del trabajo realizado en la prueba DataTech, se elaboró una propuesta técnica para optimizar la plataforma de datos de TOUS. El repositorio GPC_Tous-main centraliza APIs Flask y DAGs de Airflow en una arquitectura monolítica, con fuerte acoplamiento entre componentes, configuración dispersa y despliegues manuales.
										</p>
										</p>
										<p>
											El análisis identificó como <strong>principales problemáticas: la ausencia de CI/CD, queries de BigQuery embebidas en código, uso de operadores deprecados y una cobertura limitada de testing,</strong> afectando directamente a la mantenibilidad, escalabilidad y gobernanza de la plataforma.
										</p>
										<p>
											Como respuesta, se realizó un análisis de viabilidad técnica y se definió un roadmap de migración de 20 semanas estructurado en ocho fases. La <a href="https://github.com/Romanforns/TOUS_workframe?tab=readme-ov-file#tous-workframe" target="_blank" rel="noopener noreferrer"><strong>propuesta arquitectónica, denominada TOUS Workframe, planteó una reestructuración por capas siguiendo el patrón Medallion (Bronze-Silver-Gold), la implementación de DAG factories parametrizadas en YAML, la adopción del Repository Pattern con abstracción de Datastore y BigQuery, una estrategia metadata-driven para la gestión de queries y configuraciones, la centralización de parámetros mediante Pydantic y la incorporación de un framework de testing alineado con buenas prácticas de Data Engineering.</strong></a>
										</p>
										<p>
											El entregable consistió en una propuesta técnica integral que incluía el diseño arquitectónico detallado, el plan de migración y la documentación de mejoras estructurales, aplicando de forma coherente los patrones metadata-driven y de arquitectura consolidados durante la prueba DataTech. La propuesta buscaba reducir costes operativos, mejorar tiempos de entrega y aumentar calidad y estabilidad mediante la separación de responsabilidades, automatización de despliegues y estandarización de procesos. No obstante, <strong>la propuesta no llegó a presentarse debido a la reducción de inversión de TOUS en su Data Platform.</strong>
										</p>
									</div>
								</article>
							</div>
						</div>
					</section>

					<section id="operations" class="dimension-section collapsed">
						<h2 class="nino-sectionHeading">
							<img src="images/operations-logo.svg" alt="OPERACIONES" class="nino-icon operations-logo operations-logo-heading">OPERACIONES
						</h2>
						<div class="nino-sectionContent">
							<ul class="dimension-list">
								<li class="dimension-bullet-collapsed"><strong>DACSA</strong><span class="dimension-item-desc">Estructuración operativa de la migración a partir del assessment y del inventario de modelos e informes, definiendo el inventario de pipelines y el mapeo de datasets necesarios para la migración a Microsoft Fabric, junto con la organización del proyecto dbt en capas Staging / Silver / Gold y su integración en los flujos de despliegue mediante CI/CD en Azure Pipelines y control de versiones Git.</span></li>
								<li class="dimension-bullet-collapsed"><strong>DataTech</strong><span class="dimension-item-desc">Demostración de operación metadata-driven en la que los cambios en reglas, rutas de ingesta o destinos analíticos se realizan modificando ficheros JSON/YAML sobre una arquitectura separada en orquestación (Airflow con DAGs para coordinar ingestión RAW, validaciones y cargas), procesamiento (Spark con framework para aplicar reglas declarativas y versionado) y modelado (dbt con materialización de Data Vault y marts), garantizando trazabilidad completa desde landing hasta capas analíticas.</span></li>
								<li class="dimension-bullet-collapsed"><strong>MDIF</strong><span class="dimension-item-desc">Framework operativo que automatiza migraciones mediante descubrimiento automático de esquemas, generación de DDL y scripts de ingesta, y ejecución de procesos batch e incrementales con control de volumetría y validación de integridad, todo orquestado mediante Airflow y configurado mediante metadatos YAML.</span></li>
								<li class="dimension-bullet-collapsed"><strong>TOUS</strong><span class="dimension-item-desc">Propuesta de operar la plataforma en base a principios metadata-driven migrando gradualmente el monolito actual a componentes desacoplados, configuración centralizada mediante YAML y Pydantic, CI/CD automatizado y un framework de testing, reduciendo acoplamiento y mejorando mantenibilidad y escalabilidad.</span></li>
							</ul>
						</div>
					</section>

					<section id="team" class="dimension-section collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-account-multiple nino-icon"></i>EQUIPO
						</h2>
						<div class="nino-sectionContent">
							<ul class="dimension-list">
								<li class="dimension-bullet-collapsed"><strong>DACSA</strong><span class="dimension-item-desc"><strong>Coordinación del equipo que ejecuta el análisis detallado y la planificación de la migración</strong>, revisando entregables y alineando las decisiones técnicas del día a día con la estrategia definida, incluyendo el diseño colaborativo del proyecto dbt, sus modelos de staging y dimensiones, y las reglas de calidad y documentación mediante macros reutilizables y schemas YAML.</span></li>
								<li class="dimension-bullet-collapsed"><strong>DataTech</strong><span class="dimension-item-desc">Generación de documentación exhaustiva en repositorios (README, PROJECT_DOCUMENTATION, defensa técnica) con diagramas de arquitectura y narrativa funcional <strong>que permite a otros desarrolladores entender y extender la plataforma</strong>, facilitando la transferencia de conocimiento y la evolución del framework metadata-driven.</span></li>
								<li class="dimension-bullet-collapsed"><strong>MDIF</strong><span class="dimension-item-desc">Desarrollo de un framework reutilizable que estandariza procesos de migración, eliminando código repetitivo y proporcionando una base común para futuros proyectos de migración e ingesta, <strong>transformando aprendizajes técnicos en artefactos compartidos con potencial de convertirse en activos del equipo.</strong></span></li>
								<li class="dimension-bullet-collapsed"><strong>TOUS</strong><span class="dimension-item-desc"><strong>Referencia técnica para perfiles de datos</strong>, guiando diseño de DAGs, buenas prácticas en GCP y uso de la arquitectura actual, <strong>fomentando un marco de trabajo compartido y transferible</strong> mediante propuesta arquitectónica documentada que establece patrones y mejores prácticas aplicables a otros proyectos.</span></li>
							</ul>
						</div>
					</section>

					<section id="client" class="dimension-section collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-domain nino-icon"></i>CLIENTE
						</h2>
						<div class="nino-sectionContent">
							<ul class="dimension-list">
								<li class="dimension-bullet-collapsed"><strong>DACSA</strong><span class="dimension-item-desc"><strong>Visión clara del estado real de la plataforma de BI,</strong> dependencias entre dominios y opciones de migración a Microsoft Fabric <strong>para facilitar decisiones informadas sobre alcance, riesgos y prioridades, apoyada en un proyecto dbt gobernado con tests, documentación y despliegues automatizados</strong> que garantiza trazabilidad completa, calidad de datos mediante validaciones automatizadas y una capa analítica estructurada por dominios alineada con necesidades de reporting financiero y de gestión.</span></li>
								<li class="dimension-bullet-collapsed"><strong>TOUS</strong><span class="dimension-item-desc">Hoja de ruta clara para evolucionar la plataforma actual hacia una arquitectura más mantenible y gobernable, con propuesta técnica integral que identifica problemáticas específicas y define roadmap estructurado de migración, incluso aunque la ejecución quede condicionada por decisiones de inversión, proporcionando visión estratégica para futuras modernizaciones.</span></li>
							</ul>
						</div>
					</section>

					<section id="business" class="dimension-section collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-cash-multiple nino-icon"></i>NEGOCIO
						</h2>
						<div class="nino-sectionContent">
							<ul class="dimension-list">
								<li class="dimension-bullet-collapsed"><strong>DACSA</strong><span class="dimension-item-desc"><strong>Bases para priorizar productos y dominios según esfuerzo y valor</strong>, facilitando decisiones de inversión progresivas en la modernización de la plataforma de BI, gracias a una capa analítica en dbt estructurada por dominios y alineada con las necesidades de reporting financiero y de gestión, con optimización de rendimiento mediante carga incremental y garantía de calidad mediante tests automatizados.</span></li>
								<li class="dimension-bullet-collapsed"><strong>DataTech</strong><span class="dimension-item-desc"><strong>Conocimiento adquirido</strong> en la plataforma metadata-driven y el proyecto MDIF como activo intangible <strong>reutilizable para futuros proyectos de migración y consolidación de datos</strong>, con reducción de código específico mediante centralización de reglas en metadatos y facilidad de evolución del modelo y procesos mediante modificación de ficheros JSON/YAML, maximizando eficiencia y minimizando tiempos de desarrollo.</span></li>
								<li class="dimension-bullet-collapsed"><strong>MDIF</strong><span class="dimension-item-desc">Framework que aporta valor mediante reducción significativa de tiempo de desarrollo en migraciones, eliminación de código repetitivo, estandarización de procesos, escalabilidad para grandes volúmenes y mantenibilidad mediante configuración centralizada, <strong>consolidándose como activo reutilizable con potencial de acelerar futuros proyectos y reducir costes operativos.</strong></span></li>
								<li class="dimension-bullet-collapsed"><strong>TOUS</strong><span class="dimension-item-desc"><strong>Propuesta de refactorización orientada a reducir costes operativos, mejorar tiempos de entrega y aumentar calidad y estabilidad de la plataforma de datos</strong>, mediante separación de responsabilidades, automatización de despliegues, estandarización de procesos y framework de testing, alineando evolución técnica con objetivos de negocio y proporcionando roadmap estructurado para optimización progresiva.</span></li>
							</ul>
						</div>
					</section>

					<section id="influence" class="dimension-section collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-chart-line nino-icon"></i>INFLUENCIA
						</h2>
						<div class="nino-sectionContent">
							<ul class="dimension-list">
								<li>Influencia en decisiones arquitectónicas clave mediante documentación técnica estructurada y el diseño del proyecto dbt de DACSA (capas Silver/Gold, macros y tests), actuando como referente interno en arquitecturas de datos modernas, migraciones cloud y patrones metadata-driven aplicados a proyectos reales.</li>
								<li>Refuerzo de la posición de SDG C&R Fashion and Others como equipo capaz de ofrecer soluciones escalables y mantenibles gracias al enfoque metadata-driven, demostrado tanto en la prueba DataTech como en proyectos cliente, estableciendo estándares de calidad y mejores prácticas en diseño de plataformas de datos.</li>
								<li>Creación del MDIF como proyecto adicional, transformando aprendizajes técnicos en artefactos reutilizables con potencial de convertirse en activos del equipo, aplicando el patrón Metadata-Driven Development para simplificar migraciones futuras y consolidar conocimiento en frameworks extensibles.</li>
								<li>Influencia en la evolución de la práctica mediante propuestas técnicas como TOUS Workframe, que establecen roadmaps estructurados y patrones arquitectónicos aplicables a otros proyectos, incluso cuando la ejecución queda condicionada, proporcionando visión estratégica y marcos de referencia para modernización de plataformas legacy.</li>
							</ul>
						</div>
					</section>

					<section id="activities" class="section-collapsible collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-clipboard-text nino-icon"></i>Actividades realizadas para los clientes
						</h2>
						<div class="nino-sectionContent">
							<div class="inner">
								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Assessment Migración DACSA</h3>
									<div class="nino-articleContent">
										<p></p>
										<p><strong>Alcance</strong>: Análisis de la plataforma de datos de DACSA para evaluar y simplificar los procesos ETL de los productos de Power BI activos, como preparación de la migración a Microsoft Fabric.</p>
										<p><strong>Actividades realizadas</strong>:</p>
										<ul>
											<li><a href="https://www.notion.so/2ed09578a31780c3bebecf2738c512e8?v=814cd73ce5bd4dd892543cc6dd296145&source=copy_link" target="_blank" rel="noopener noreferrer"><strong>Documentación exhaustiva de la plataforma existente: Dynamics 365 FO como fuente principal, Azure Synapse, Azure Data Factory, MySQL</strong></a>  y SharePoint.</li>
											<li><a href="https://github.com/Romanforns/migracion_dacsa/blob/master/docs/inventario_modelos_por_dominio.md" target="_blank" rel="noopener noreferrer"><strong>Inventario de modelos semánticos y reportes paginados</strong></a>, con documentación por producto.</li>
											<li>Modelado por dominios (Finanzas, Logística, Ventas, Calidad, I+D, POE) con identificación de hechos y dimensiones clave.</li>
											<li><a href="https://docs.google.com/spreadsheets/d/1jjGVUZ-GT-S37_2Pfa-CA0RfkMlHH7aloJaicl6n3Os/edit?gid=372288029#gid=372288029" target="_blank" rel="noopener noreferrer"><strong>Categorización de productos (S, M, L, XL)</strong></a> según complejidad y esfuerzo para priorizar y estimar la migración.</li>
											<li>Definición de estrategia preliminar de migración basada en consumo desde shortcuts de Fabric, modelado en dbt y simplificación de capas intermedias.</li>
										</ul>
									</div>
								</article>

								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Proyecto Migración DACSA Fabric</h3>
									<div class="nino-articleContent">
										<p></p>
										<p><strong>Alcance</strong>: Análisis y diseño para migrar la plataforma de datos de DACSA a Microsoft Fabric.</p>
										<p><strong>Actividades realizadas</strong>:</p>
										<ul>
											<li><a href="https://www.notion.so/2f109578a31780d9aa94c7ab12bc6cbb?v=8bf3792f054e47619be7979aa84f4c4b" target="_blank" rel="noopener noreferrer"><strong>Inventario de pipelines</strong></a> y mapeo de datasets desde el <a href="https://www.notion.so/2f109578a317806985fce23ca773c3da?v=d84069fd8b194697baaac36f06595113" target="_blank" rel="noopener noreferrer"><strong>repositorio de análisis</strong></a>.</li>
											<li>Elaboración de <a href="https://www.notion.so/D365-F-O-Fields-Glossary-2e809578a3178025958dd57beab01778" target="_blank" rel="noopener noreferrer"><strong>glosario de campos D365 F&amp;O y documentación de entidades clave</strong></a>, alineando el modelo técnico con el lenguaje de negocio.</li>
											<li><a href="https://www.notion.so/2ea09578a31780afada9f70242653694?v=d8db50c1ab6d4ad7ba0539774aa1aa32&source=copy_link" target="_blank" rel="noopener noreferrer"><strong>Documentación de modelos BIM</strong></a>.</li>
											<li><a href="https://www.notion.so/FINANZAS-2e709578a317808b878af68c01e71fc1" target="_blank" rel="noopener noreferrer"><strong>Definición de capas de transformación y su mapeo hacia las capas Bronze/Silver/Gold</strong></a>, integrando la estrategia de calidad de datos.</li>
										</ul>
									</div>
								</article>

								<article class="dimension-bullet-collapsed">
									<h3 class="nino-articleTitle">Proyecto Modelado DACSA con dbt</h3>
									<div class="nino-articleContent">
										<p></p>
										<p><strong>Alcance</strong>: Proyecto de modelado analítico con dbt orientado a construir una capa de datos gobernada y documentada para reporting financiero y de gestión en DACSA, estructurando información procedente de Dynamics 365 F&amp;O y SharePoint mediante modelos escalonados (staging / silver / gold).</p>
										<p><strong>Actividades realizadas</strong>:</p>
										<ul>
											<li><strong>Diseño y estructuración del proyecto dbt</strong>: definición de la jerarquía Silver/Gold, configuración de fuentes mediante <code>sources.yml</code>, paquetes mediante <code>packages.yml</code> (dbt_utils, dbt_expectations) y configuración general mediante <code>dbt_project.yml</code> y <code>profiles.yml</code>.</li>
											<li><strong>Modelado de capa Silver / Staging</strong>: creación de 25+ modelos SQL de transformación en <code>models/Silver/Staging/staging_dynamics</code> para entidades clave (clientes, proveedores, productos, contabilidad, localizaciones, parámetros del sistema) y en <code>models/Silver/Staging/staging_sharepoint</code> para información complementaria de actividad financiera.</li>
											<li><strong>Modelado de capa Gold / Dimensions</strong>: construcción de dimensiones de negocio en <code>models/Gold/Dimensions</code> (calendario fiscal, productos, proveedores, compañías, cuentas analíticas) orientadas a servir de base a cuadros de mando financieros y de gestión.</li>
											<li><strong>Calidad y gobernanza de datos</strong>: implementación de <code>schema.yml</code> con tests de integridad (not_null, unique), descripciones estructuradas y control de integridad referencial entre modelos, con configuración de severidad de tests (warn/error) y validación mediante dbt_expectations.</li>
											<li><strong>Estandarización mediante macros</strong>: desarrollo de macros reutilizables en <code>macros/</code> para generación automática de metadatos de trazabilidad (<code>silver_metadata</code>), limpieza y normalización de datos (<code>stg_clean</code>), filtros incrementales para optimización de procesamiento y generación de surrogate keys.</li>
											<li><strong>Integración en CI/CD</strong>: participación en la integración del proyecto dbt con pipelines de despliegue en Azure Pipelines y flujos de trabajo Git para promover cambios de forma trazable y gobernada, facilitando despliegues automatizados y control de versiones.</li>
										</ul>
									</div>
								</article>
							</div>
						</div>
					</section>

					<section id="future" class="section-collapsible collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-timer-sand nino-icon"></i>¿Cómo te gustaría verte dentro de 6 meses en SDG?
						</h2>
						<div class="nino-sectionContent">
							<p>
								Me gustaría verme <strong>consolidando el paso a Specialist de arquitectura e integración</strong> en el equipo C&R - Fashion and Others, con foco en:
							</p>
							<ul>
								<li><strong>Arquitecturas innovadoras</strong> de datos metadata-driven, incorporando progresivamente capacidades de IA y Machine Learning cuando aporten valor real.</li>
								<li>Migraciones de entornos legacy hacia ecosistemas cloud con trazabilidad, calidad y gobernanza.</li>
								<li><strong>Soluciones de arqutectura que unan eficiencia tecnológica y visión de negocio</strong>, reutilizando patrones y frameworks para maximizar impacto en costes, riesgos, tiempos de entrega y calidad del dato.</li>
								<li>Continuar inspirando y guiando a los miembros de los equipos en los proyectos, <strong>acompañando a perfiles más junior mediante liderazgo interno</strong>.</li>
							</ul>
						</div>
					</section>

					<section id="growth-factors" class="section-collapsible collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-rocket nino-icon"></i>Factores clave para seguir creciendo
						</h2>
						<div class="nino-sectionContent">
							<ul>
								<li><strong>Proyectos high-tech</strong>: Retos que exijan dominar nuevas tecnologías y patrones de arquitectura de datos.</li>
								<li><strong>Colaboración</strong> con referentes técnicos senior para <strong>enriquecer la visión en arquitectura y gobierno del dato</strong>.</li>
								<li><strong>Mayor disponibilidad para diseño</strong>: reducir dedicación exclusiva a desarrollo para poder diseñar arquitecturas desde la fase de propuesta y assessment, mejorar prácticas y documentación, y formar a analistas y consultores.</li>
								<li><strong>Reutilización de artefactos</strong>: trabajar en desarrollos que permitan reaprovechamiento de soluciones como <strong>base para acelerar futuros proyectos</strong>.</li>
							</ul>
						</div>
					</section>

					<section id="personal-comment" class="section-collapsible collapsed">
						<h2 class="nino-sectionHeading">
							<i class="mdi mdi-comment-text nino-icon"></i>Comentario personal
						</h2>
						<div class="nino-sectionContent">
							<p>
								En este periodo he pasado de centrarme en el desarrollo a tener un rol más orientado a diseño de arquitecturas de datos y roadmaps de migración, definiendo plataformas metadata-driven, modelos Data Vault y frameworks reutilizables (con la prueba DataTech, el MDIF o la propuesta de TOUS).
							</p>
							<p>
								Además de la contribución técnica, he mantenido la coordinación de iniciativas, la orientación de perfiles más junior y la generación de documentación estructural de referencia.
							</p>
							<p>
								Al mismo tiempo, la naturaleza de las responsabilidades asumidas, el tipo de decisiones en las que participo y el nivel de autonomía que ejerzo han evolucionado significativamente, reflejando una progresión técnica constante y una mayor capacidad para abordar retos de creciente complejidad desde una perspectiva arquitectónica y estratégica. En ocasiones, esta evolución se ha producido a un ritmo superior al de la propia estructuración formal de los contextos, oportunidades y reconocimientos.
							</p>
							<p>
								Este contraste me lleva a reflexionar sobre la necesidad de identificar espacios donde mi contribución pueda evolucionar de forma proporcional a la complejidad y al impacto de los retos que estoy en condiciones de abordar, asegurando una trayectoria coherente con el potencial y el compromiso demostrado.
							</p>
						</div>
					</section>
				</main>
			</div>
		</div>
	</div>

	<a href="#" id="nino-scrollToTop">Go to Top</a>

	<script type="text/javascript" src="js/jquery.min.js"></script>
	<script type="text/javascript" src="js/bootstrap.min.js"></script>
	<script type="text/javascript" src="js/template.js"></script>
	<script type="text/javascript">
		// Desplegables para secciones (dimension-section y section-collapsible)
		(function () {
			var sections = document.querySelectorAll('#dimensions-growth ~ .dimension-section, .section-collapsible');
			sections.forEach(function (section) {
				var heading = section.querySelector('.nino-sectionHeading');
				if (!heading) return;

				heading.addEventListener('click', function () {
					section.classList.toggle('collapsed');
				});
			});
		})();

		// Al clicar en el ribbon: expandir sección y centrar en la vista
		(function () {
			var dimensionIds = ['practice', 'operations', 'team', 'client', 'business', 'influence'];
			document.querySelectorAll('#mainMenu a.topBar[href^="#"]').forEach(function (link) {
				link.addEventListener('click', function (e) {
					var href = this.getAttribute('href');
					if (!href || href === '#') return;
					var id = href.slice(1);
					var target = document.getElementById(id);
					if (!target) return;
					e.preventDefault();
					// Si es una dimensión, expandir Dimensiones del crecimiento profesional
					if (dimensionIds.indexOf(id) !== -1) {
						var dimensionsGrowth = document.getElementById('dimensions-growth');
						if (dimensionsGrowth) dimensionsGrowth.classList.remove('collapsed');
					}
					// Expandir la sección objetivo si está colapsada
					if (target.classList.contains('section-collapsible') || target.classList.contains('dimension-section')) {
						target.classList.remove('collapsed');
					}
					// Centrar en la vista
					target.scrollIntoView({ behavior: 'smooth', block: 'start' });
					history.replaceState(null, null, href);
				});
			});
		})();

		// Desplegables por bullet dentro de cada dimensión (Practice, Actividades y listas DACSA/DataTech/TOUS)
		(function () {
			// Practice y Actividades: cada artículo
			document.querySelectorAll('#practice .inner article, #activities .inner article').forEach(function (article) {
				var title = article.querySelector('.nino-articleTitle');
				if (!title) return;
				title.addEventListener('click', function () {
					article.classList.toggle('dimension-bullet-collapsed');
				});
			});
			// OPERACIONES, Team, Client, Business: cada ítem de lista
			document.querySelectorAll('.dimension-list li').forEach(function (li) {
				var trigger = li.querySelector('strong');
				if (!trigger) return;
				trigger.addEventListener('click', function () {
					li.classList.toggle('dimension-bullet-collapsed');
				});
			});
		})();
	</script>
</body>
</html>
